layer_sizes:
  in_size: 655
  out_size: 11

model1:
  layer_sizes:
  in_size: 655
  out_size: 11

  training_params:
    episodes: 10_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.06
      epsilon_min: 0.01
      mini_batch_size: 128
      steps_between_optimization: 128
      updates_between_target_sync: 300
      learning_rate_a: 0.0001 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 512
      hidden_layer2_size: 1024
      hidden_layer3_size: 512
      hidden_layer4_size: 1024
      output_layer_size: 11
      enable_double_dqn: False

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 128
      steps_between_optimization: 128
      learning_rate_a: 0.1 #min to avoid nan outputs from nn
      input_layer_size: 655
      hidden_layer1_size: 512
      hidden_layer2_size: 1024
      hidden_layer3_size: 512
      hidden_layer4_size: 1024
      output_layer_size: 11
  
model2:
  training_params:
    episodes: 100_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.13
      epsilon_min: 0
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.0001 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      min_prob_of_replacing_reservoir: 0.25
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
      enable_double_dqn: True

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 256
      steps_between_optimization: 256
      learning_rate_a: 0.05 #min to avoid nan outputs from nn
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
    
  exploitability_testing_params:
    episodes: 10000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.0
      epsilon_min: 0
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.0001 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      min_prob_of_replacing_reservoir: 0.25
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
      enable_double_dqn: True

model3:
  training_params:
    episodes: 100_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.13
      epsilon_min: 0
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.1 
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
      enable_double_dqn: True

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 256
      steps_between_optimization: 256
      learning_rate_a: 0.001 
      min_prob_of_replacing_reservoir: 0.05 #
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11

  exploitability_testing_params:
    episodes: 40000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.0
      epsilon_min: 0
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.01
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
      enable_double_dqn: True

model4:
  training_params:
    episodes: 100_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.06
      epsilon_min: 0
      mini_batch_size: 1024
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.0001 
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 4096
      hidden_layer2_size: 2048
      hidden_layer3_size: 4096
      hidden_layer4_size: 2048
      output_layer_size: 11
      enable_double_dqn: True

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 1024
      steps_between_optimization: 256
      learning_rate_a: 0.01
      min_prob_of_replacing_reservoir: 0.05 #
      input_layer_size: 655
      hidden_layer1_size: 4096
      hidden_layer2_size: 2048
      hidden_layer3_size: 4096
      hidden_layer4_size: 2048
      output_layer_size: 11

  exploitability_testing_params:
    episodes: 10000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.0
      epsilon_min: 0
      mini_batch_size: 1024
      steps_between_optimization: 2560000
      updates_between_target_sync: 1000000
      learning_rate_a: 0.0000
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 4096
      hidden_layer2_size: 2048
      hidden_layer3_size: 4096
      hidden_layer4_size: 2048
      output_layer_size: 11
      enable_double_dqn: True

model5:
  #
  training_params:
    episodes: 100_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.13
      epsilon_min: 0
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.0001 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512 #4 more times
      output_layer_size: 11
      enable_double_dqn: True

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 256
      steps_between_optimization: 256
      learning_rate_a: 0.1 #min to avoid nan outputs from nn
      min_prob_of_replacing_reservoir: 0.05
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512 #4 more times
      output_layer_size: 11
    
  exploitability_testing_params:
    episodes: 10000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.0
      epsilon_min: 0
      mini_batch_size: 256000000
      steps_between_optimization: 2560000 #not used
      updates_between_target_sync: 1000
      learning_rate_a: 0.01 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 1024
      hidden_layer2_size: 512
      hidden_layer3_size: 1024
      hidden_layer4_size: 512
      output_layer_size: 11
      enable_double_dqn: True

model6:
  training_params:
    episodes: 100_000_000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.13
      epsilon_min: 0.001
      mini_batch_size: 256
      steps_between_optimization: 256
      updates_between_target_sync: 1000
      learning_rate_a: 0.0001 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 0.1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 512
      hidden_layer2_size: 256
      hidden_layer3_size: 128
      hidden_layer4_size: 64
      output_layer_size: 11
      enable_double_dqn: True

    classification_params:
      reservoir_memory_size: 200000
      mini_batch_size: 256
      steps_between_optimization: 256
      learning_rate_a: 0.01 #min to avoid nan outputs from nn
      min_prob_of_replacing_reservoir: 0.05
      input_layer_size: 655
      hidden_layer1_size: 512
      hidden_layer2_size: 256
      hidden_layer3_size: 128
      hidden_layer4_size: 64
      output_layer_size: 11

  exploitability_testing_params:
    episodes: 40000
    dqn_params:
      replay_memory_size: 100000
      epsilon_init: 0.0
      epsilon_min: 0
      mini_batch_size: 256000000
      steps_between_optimization: 2560000 #not used
      updates_between_target_sync: 1000000
      learning_rate_a: 0.00 #minimum to avoid nan outputs from nn
      discount_factor_g: 0.99
      anticipatory_parameter: 1 #no cambiar 
      input_layer_size: 655
      hidden_layer1_size: 512
      hidden_layer2_size: 256
      hidden_layer3_size: 128
      hidden_layer4_size: 64
      output_layer_size: 11
      enable_double_dqn: True